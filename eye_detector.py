import cv2
import numpy as np
import time
from collections import deque
from PIL import Image, ImageDraw, ImageFont
import os
import urllib.request

import mediapipe as mp
from mediapipe.tasks import python
from mediapipe.tasks.python import vision


class ModernMediaPipeEyeDetector:
    def __init__(self):
        # ===== –ü–ï–†–ï–ú–ï–ù–ù–´–ï –î–õ–Ø –ì–õ–ê–ó =====
        # –ò–Ω–¥–µ–∫—Å—ã –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫ –¥–ª—è –≥–ª–∞–∑
        self.LEFT_EYE_INDICES = [33, 133, 157, 158, 159, 160, 161, 173]
        self.RIGHT_EYE_INDICES = [362, 263, 387, 386, 385, 384, 398, 466]

        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ–≥–æ –∏–∑–º–µ—Ä–µ–Ω–∏—è
        # –î–ª—è –ª–µ–≤–æ–≥–æ –≥–ª–∞–∑–∞: –≤–µ—Ä—Ö–Ω–µ–µ –≤–µ–∫–æ (159), –Ω–∏–∂–Ω–µ–µ –≤–µ–∫–æ (145)
        # –î–ª—è –ø—Ä–∞–≤–æ–≥–æ –≥–ª–∞–∑–∞: –≤–µ—Ä—Ö–Ω–µ–µ –≤–µ–∫–æ (386), –Ω–∏–∂–Ω–µ–µ –≤–µ–∫–æ (374)
        self.LEFT_EYE_VERTICAL = [159, 145]  # –≤–µ—Ä—Ö–Ω—è—è –∏ –Ω–∏–∂–Ω—è—è —Ç–æ—á–∫–∏
        self.RIGHT_EYE_VERTICAL = [386, 374]  # –≤–µ—Ä—Ö–Ω—è—è –∏ –Ω–∏–∂–Ω—è—è —Ç–æ—á–∫–∏

        # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–≥–æ –∏–∑–º–µ—Ä–µ–Ω–∏—è (—É–≥–æ–ª–∫–∏ –≥–ª–∞–∑)
        self.LEFT_EYE_HORIZONTAL = [33, 133]  # –≤–Ω–µ—à–Ω–∏–π –∏ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π —É–≥–æ–ª–∫–∏
        self.RIGHT_EYE_HORIZONTAL = [362, 263]  # –≤–Ω–µ—à–Ω–∏–π –∏ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π —É–≥–æ–ª–∫–∏

        # ===== –ü–ï–†–ï–ú–ï–ù–ù–´–ï –î–õ–Ø –°–¢–ê–ë–ò–õ–ò–ó–ê–¶–ò–ò =====
        self.ear_history = deque(maxlen=5)
        self.face_history = deque(maxlen=5)
        self.confirmation_threshold = 3

        # ===== –ü–ï–†–ï–ú–ï–ù–ù–´–ï –°–û–°–¢–û–Ø–ù–ò–Ø =====
        self.eyes_closed_start = None
        self.alert_threshold = 2
        self.total_blinks = 0
        self.prev_eye_state = True
        self.last_state_change = 0
        self.state_change_delay = 0.2

        # ===== –ü–û–†–û–ì –ò–ó –í–ê–®–ò–• –î–ê–ù–ù–´–• =====
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤–∞—à–∏ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è —Ç–æ—á–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        self.ear_open = 0.17
        self.ear_closed = 0.13

        # –í—ã—á–∏—Å–ª—è–µ–º –ø–æ—Ä–æ–≥ (—á—É—Ç—å –≤—ã—à–µ —Å—Ä–µ–¥–Ω–µ–≥–æ –º–µ–∂–¥—É –æ—Ç–∫—Ä—ã—Ç—ã–º–∏ –∏ –∑–∞–∫—Ä—ã—Ç—ã–º–∏)
        self.eye_threshold = (self.ear_open + self.ear_closed) / 2
        print(f"–ü–æ—Ä–æ–≥ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {self.eye_threshold:.3f}")

        # ===== –î–õ–Ø –†–£–°–°–ö–ò–• –ë–£–ö–í =====
        self.setup_russian_font()

        # ===== –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø MEDIAPIPE =====
        self.setup_mediapipe()

        print("\n" + "=" * 50)
        print("–î–ï–¢–ï–ö–¢–û–† –ó–ê–ü–£–©–ï–ù")
        print(f"MediaPipe version: {mp.__version__}")
        print("=" * 50)
        print(f"EAR –æ—Ç–∫—Ä—ã—Ç—ã—Ö: {self.ear_open}")
        print(f"EAR –∑–∞–∫—Ä—ã—Ç—ã—Ö: {self.ear_closed}")
        print(f"–ü–æ—Ä–æ–≥: {self.eye_threshold}")
        print("=" * 50)

    def download_model(self):
        """–°–∫–∞—á–∏–≤–∞–µ—Ç –º–æ–¥–µ–ª—å FaceLandmarker –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç"""
        model_url = "https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task"
        model_path = "face_landmarker.task"

        if not os.path.exists(model_path):
            print("–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ FaceLandmarker...")
            try:
                urllib.request.urlretrieve(model_url, model_path)
                print("‚úì –ú–æ–¥–µ–ª—å —Å–∫–∞—á–∞–Ω–∞")
            except Exception as e:
                print(f"‚úó –û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: {e}")
                return None

        return model_path

    def setup_mediapipe(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ MediaPipe"""
        try:
            model_path = self.download_model()
            if model_path is None:
                raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –º–æ–¥–µ–ª—å")

            base_options = python.BaseOptions(model_asset_path=model_path)
            options = vision.FaceLandmarkerOptions(
                base_options=base_options,
                running_mode=vision.RunningMode.VIDEO,
                num_faces=1,
                min_face_detection_confidence=0.3,
                min_face_presence_confidence=0.3,
                min_tracking_confidence=0.3,
                output_face_blendshapes=False,
                output_facial_transformation_matrixes=False,
            )

            self.detector = vision.FaceLandmarker.create_from_options(options)
            print("‚úì MediaPipe –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞ MediaPipe: {e}")
            print("–ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥...")
            self.setup_simple_mediapipe()

    def setup_simple_mediapipe(self):
        """–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ —Å –ø—Ä–æ—Å—Ç—ã–º FaceMesh"""
        try:
            self.mp_face_mesh = mp.solutions.face_mesh
            self.face_mesh = self.mp_face_mesh.FaceMesh(
                static_image_mode=False,
                max_num_faces=1,
                refine_landmarks=True,
                min_detection_confidence=0.3,
                min_tracking_confidence=0.3
            )
            self.use_simple_mp = True
            print("‚úì –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–æ—Å—Ç–æ–π FaceMesh")
        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞: {e}")
            raise

    def setup_russian_font(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —à—Ä–∏—Ñ—Ç–∞ –¥–ª—è —Ä—É—Å—Å–∫–∏—Ö –±—É–∫–≤"""
        try:
            font_paths = [
                "C:/Windows/Fonts/arial.ttf",
                "C:/Windows/Fonts/Calibri.ttf",
            ]

            self.font = None
            for path in font_paths:
                if os.path.exists(path):
                    self.font = ImageFont.truetype(path, 32)
                    self.font_small = ImageFont.truetype(path, 24)
                    self.font_big = ImageFont.truetype(path, 48)
                    break

            if self.font is None:
                self.font = ImageFont.load_default()

            self.use_pil = True
        except:
            self.use_pil = False

    def put_russian_text(self, img, text, position, size=32, color=(255, 255, 255)):
        """–†–∏—Å—É–µ—Ç —Ä—É—Å—Å–∫–∏–π —Ç–µ–∫—Å—Ç"""
        if not self.use_pil:
            cv2.putText(img, text, position, cv2.FONT_HERSHEY_SIMPLEX,
                        size / 20, color, 2)
            return img

        try:
            img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
            draw = ImageDraw.Draw(img_pil)

            if size >= 48:
                font = self.font_big
            elif size >= 32:
                font = self.font
            else:
                font = self.font_small

            draw.text(position, text, font=font, fill=color[::-1])
            return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)
        except:
            cv2.putText(img, text, position, cv2.FONT_HERSHEY_SIMPLEX,
                        size / 20, color, 2)
            return img

    def calculate_ear(self, landmarks, vertical_idx, horizontal_idx, frame_shape):
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç Eye Aspect Ratio (EAR)
        –ß–µ–º –º–µ–Ω—å—à–µ –∑–Ω–∞—á–µ–Ω–∏–µ - —Ç–µ–º –±–æ–ª–µ–µ –∑–∞–∫—Ä—ã—Ç –≥–ª–∞–∑
        """
        h, w = frame_shape[:2]

        try:
            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Ç–æ—á–µ–∫
            if hasattr(landmarks, 'landmark'):
                v1 = landmarks.landmark[vertical_idx[0]]
                v2 = landmarks.landmark[vertical_idx[1]]
                h1 = landmarks.landmark[horizontal_idx[0]]
                h2 = landmarks.landmark[horizontal_idx[1]]
            else:
                v1 = landmarks[vertical_idx[0]]
                v2 = landmarks[vertical_idx[1]]
                h1 = landmarks[horizontal_idx[0]]
                h2 = landmarks[horizontal_idx[1]]

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –ø–∏–∫—Å–µ–ª–∏
            v1_point = np.array([v1.x * w, v1.y * h])
            v2_point = np.array([v2.x * w, v2.y * h])
            h1_point = np.array([h1.x * w, h1.y * h])
            h2_point = np.array([h2.x * w, h2.y * h])

            # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
            vertical_dist = np.linalg.norm(v1_point - v2_point)
            horizontal_dist = np.linalg.norm(h1_point - h2_point)

            # EAR = –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ / –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ
            ear = vertical_dist / (horizontal_dist + 1e-6)

            # –ò–ù–í–ï–†–¢–ò–†–£–ï–ú –µ—Å–ª–∏ –Ω—É–∂–Ω–æ (–µ—Å–ª–∏ –≤–∞—à–∏ –¥–∞–Ω–Ω—ã–µ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –æ–±—Ä–∞—Ç–Ω–æ–µ)
            # –ù–æ –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å, –ø—Ä–æ—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤–∞—à –ø–æ—Ä–æ–≥
            return ear

        except Exception as e:
            return 0.3

    def draw_eye_points(self, frame, landmarks, eye_indices, color):
        """–†–∏—Å—É–µ—Ç —Ç–æ—á–∫–∏ –≤–æ–∫—Ä—É–≥ –≥–ª–∞–∑"""
        h, w = frame.shape[:2]

        try:
            for idx in eye_indices:
                if hasattr(landmarks, 'landmark'):
                    landmark = landmarks.landmark[idx]
                else:
                    landmark = landmarks[idx]
                x = int(landmark.x * w)
                y = int(landmark.y * h)
                cv2.circle(frame, (x, y), 2, color, -1)
        except:
            pass

    def process_frame(self, frame):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞"""
        if hasattr(self, 'use_simple_mp') and self.use_simple_mp:
            return self.process_frame_simple(frame)
        else:
            return self.process_frame_new(frame)

    def process_frame_new(self, frame):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞ —á–µ—Ä–µ–∑ –Ω–æ–≤—ã–π API"""
        try:
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)

            current_time_ms = int(time.time() * 1000)
            detection_result = self.detector.detect_for_video(mp_image, current_time_ms)

            face_detected = False
            ear_value = 0.3

            if detection_result.face_landmarks:
                face_detected = True
                landmarks = detection_result.face_landmarks[0]

                left_ear = self.calculate_ear(
                    landmarks,
                    self.LEFT_EYE_VERTICAL,
                    self.LEFT_EYE_HORIZONTAL,
                    frame.shape
                )

                right_ear = self.calculate_ear(
                    landmarks,
                    self.RIGHT_EYE_VERTICAL,
                    self.RIGHT_EYE_HORIZONTAL,
                    frame.shape
                )

                ear_value = (left_ear + right_ear) / 2.0

                # –†–∏—Å—É–µ–º —Ç–æ—á–∫–∏
                self.draw_eye_points(frame, landmarks, self.LEFT_EYE_INDICES, (0, 255, 0))
                self.draw_eye_points(frame, landmarks, self.RIGHT_EYE_INDICES, (0, 255, 0))

            return frame, face_detected, ear_value
        except Exception as e:
            return frame, False, 0.3

    def process_frame_simple(self, frame):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞ —á–µ—Ä–µ–∑ –ø—Ä–æ—Å—Ç–æ–π FaceMesh"""
        try:
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = self.face_mesh.process(rgb_frame)

            face_detected = False
            ear_value = 0.3

            if results.multi_face_landmarks:
                face_detected = True
                landmarks = results.multi_face_landmarks[0]

                left_ear = self.calculate_ear(
                    landmarks,
                    self.LEFT_EYE_VERTICAL,
                    self.LEFT_EYE_HORIZONTAL,
                    frame.shape
                )

                right_ear = self.calculate_ear(
                    landmarks,
                    self.RIGHT_EYE_VERTICAL,
                    self.RIGHT_EYE_HORIZONTAL,
                    frame.shape
                )

                ear_value = (left_ear + right_ear) / 2.0

                self.draw_eye_points(frame, landmarks, self.LEFT_EYE_INDICES, (0, 255, 0))
                self.draw_eye_points(frame, landmarks, self.RIGHT_EYE_INDICES, (0, 255, 0))

            return frame, face_detected, ear_value
        except Exception as e:
            return frame, False, 0.3

    def run(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª"""
        cap = cv2.VideoCapture(0)
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

        prev_time = time.time()
        fps = 0

        while True:
            ret, frame = cap.read()
            if not ret:
                break

            current_time = time.time()
            fps = 1 / (current_time - prev_time)
            prev_time = current_time

            frame = cv2.flip(frame, 1)

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞
            frame, face_detected, ear_value = self.process_frame(frame)

            # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é
            self.face_history.append(face_detected)
            self.ear_history.append(ear_value)

            # –°–≥–ª–∞–∂–µ–Ω–Ω—ã–π EAR
            smoothed_ear = sum(self.ear_history) / len(self.ear_history)

            # –°—Ç–∞–±–∏–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ª–∏—Ü–∞
            stable_face = sum(self.face_history) >= self.confirmation_threshold

            # –õ–æ–≥–∏–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è
            if stable_face:
                # –ò–°–ü–†–ê–í–õ–ï–ù–û: –≥–ª–∞–∑–∞ –∑–∞–∫—Ä—ã—Ç—ã, –µ—Å–ª–∏ EAR –ú–ï–ù–¨–®–ï –ø–æ—Ä–æ–≥–∞
                eyes_closed = smoothed_ear < self.eye_threshold

                if current_time - self.last_state_change > self.state_change_delay:

                    if eyes_closed:
                        # –ì–õ–ê–ó–ê –ó–ê–ö–†–´–¢–´
                        if self.eyes_closed_start is None:
                            self.eyes_closed_start = current_time
                            self.last_state_change = current_time

                            # –ü–æ–¥—Å—á–µ—Ç –º–æ—Ä–≥–∞–Ω–∏—è (–ø–µ—Ä–µ—Ö–æ–¥ –æ—Ç–∫—Ä—ã—Ç–æ -> –∑–∞–∫—Ä—ã—Ç–æ)
                            if self.prev_eye_state:
                                self.total_blinks += 1
                                print(f"üëÅ –ú–æ—Ä–≥! –í—Å–µ–≥–æ: {self.total_blinks}")

                            self.prev_eye_state = False

                        closed_duration = current_time - self.eyes_closed_start

                        frame = self.put_russian_text(
                            frame,
                            f"–ì–õ–ê–ó–ê –ó–ê–ö–†–´–¢–´! {closed_duration:.1f}—Å",
                            (50, 50), 36, (0, 0, 255)
                        )

                        if closed_duration > self.alert_threshold:
                            frame = self.put_russian_text(
                                frame,
                                "‚ö† –ü–†–û–°–ù–ò–¢–ï–°–¨! ‚ö†",
                                (50, 100), 48, (0, 0, 255)
                            )
                    else:
                        # –ì–õ–ê–ó–ê –û–¢–ö–†–´–¢–´
                        if self.eyes_closed_start is not None:
                            self.last_state_change = current_time

                        self.eyes_closed_start = None
                        self.prev_eye_state = True

                        frame = self.put_russian_text(
                            frame,
                            "–ì–õ–ê–ó–ê –û–¢–ö–†–´–¢–´",
                            (50, 50), 36, (0, 255, 0)
                        )
            else:
                frame = self.put_russian_text(
                    frame,
                    "–õ–ò–¶–û –ù–ï –û–ë–ù–ê–†–£–ñ–ï–ù–û",
                    (50, 50), 32, (128, 128, 128)
                )

            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
            stats = [
                f"–ú–æ—Ä–≥–∞–Ω–∏–π: {self.total_blinks}",
                f"EAR: {smoothed_ear:.3f}",
                f"–ü–æ—Ä–æ–≥: {self.eye_threshold:.3f}",
                f"–°–æ—Å—Ç–æ—è–Ω–∏–µ: {'–ó–ê–ö–†–´–¢–´' if smoothed_ear < self.eye_threshold else '–û–¢–ö–†–´–¢–´'}"
            ]

            for i, stat in enumerate(stats):
                frame = self.put_russian_text(
                    frame, stat, (50, 150 + i * 30), 24, (255, 255, 255)
                )

            # –ì—Ä–∞—Ñ–∏–∫
            self.draw_ear_graph(frame, smoothed_ear, self.eye_threshold)

            # –ü–æ–¥—Å–∫–∞–∑–∫–∏
            frame = self.put_russian_text(
                frame, "ESC - –≤—ã—Ö–æ–¥ | R - —Å–±—Ä–æ—Å", (50, 460), 20, (150, 150, 150)
            )

            cv2.imshow('Eye Detector', frame)

            key = cv2.waitKey(1) & 0xFF
            if key == 27:
                break
            elif key == ord('r') or key == ord('–∫'):
                self.total_blinks = 0
                print("–°—á–µ—Ç—á–∏–∫ —Å–±—Ä–æ—à–µ–Ω")

        cap.release()
        cv2.destroyAllWindows()

        print(f"\n–í—Å–µ–≥–æ –º–æ—Ä–≥–∞–Ω–∏–π: {self.total_blinks}")

    def draw_ear_graph(self, frame, current_ear, threshold):
        """–†–∏—Å—É–µ—Ç –≥—Ä–∞—Ñ–∏–∫ EAR"""
        graph_x = 50
        graph_y = 350
        graph_w = 400
        graph_h = 30

        # –§–æ–Ω
        cv2.rectangle(frame, (graph_x, graph_y),
                      (graph_x + graph_w, graph_y + graph_h),
                      (50, 50, 50), -1)
        cv2.rectangle(frame, (graph_x, graph_y),
                      (graph_x + graph_w, graph_y + graph_h),
                      (200, 200, 200), 1)

        # –¢–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ (EAR –æ–±—ã—á–Ω–æ –æ—Ç 0 –¥–æ 0.5)
        bar_width = int((current_ear / 0.5) * graph_w)
        bar_width = min(bar_width, graph_w)

        # –¶–≤–µ—Ç: –∑–µ–ª–µ–Ω—ã–π –µ—Å–ª–∏ –æ—Ç–∫—Ä—ã—Ç—ã (EAR > –ø–æ—Ä–æ–≥), –∫—Ä–∞—Å–Ω—ã–π –µ—Å–ª–∏ –∑–∞–∫—Ä—ã—Ç—ã
        color = (0, 255, 0) if current_ear > threshold else (0, 0, 255)
        cv2.rectangle(frame, (graph_x, graph_y),
                      (graph_x + bar_width, graph_y + graph_h),
                      color, -1)

        # –û—Ç–º–µ—Ç–∫–∞ –ø–æ—Ä–æ–≥–∞
        threshold_x = graph_x + int((threshold / 0.5) * graph_w)
        cv2.line(frame, (threshold_x, graph_y - 5),
                 (threshold_x, graph_y + graph_h + 5),
                 (255, 255, 0), 2)

        # –ü–æ–¥–ø–∏—Å–∏
        cv2.putText(frame, f"EAR: {current_ear:.3f}", (graph_x, graph_y - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)


if __name__ == "__main__":
    detector = ModernMediaPipeEyeDetector()
    detector.run()