import cv2
import numpy as np
import time
from collections import deque
from PIL import Image, ImageDraw, ImageFont
import os
import urllib.request
import threading  # –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –≤–∏–¥–µ–æ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ

import mediapipe as mp
from mediapipe.tasks import python
from mediapipe.tasks.python import vision


class ModernMediaPipeEyeDetector:
    def __init__(self):
        # ===== –ü–ï–†–ï–ú–ï–ù–ù–´–ï –î–õ–Ø –ì–õ–ê–ó =====
        # –ò–Ω–¥–µ–∫—Å—ã –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫ –¥–ª—è –≥–ª–∞–∑
        self.LEFT_EYE_INDICES = [33, 133, 157, 158, 159, 160, 161, 173]
        self.RIGHT_EYE_INDICES = [362, 263, 387, 386, 385, 384, 398, 466]

        # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ–≥–æ –∏–∑–º–µ—Ä–µ–Ω–∏—è
        self.LEFT_EYE_VERTICAL = [159, 145]
        self.RIGHT_EYE_VERTICAL = [386, 374]

        # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–≥–æ –∏–∑–º–µ—Ä–µ–Ω–∏—è
        self.LEFT_EYE_HORIZONTAL = [33, 133]
        self.RIGHT_EYE_HORIZONTAL = [362, 263]

        # ===== –ü–ï–†–ï–ú–ï–ù–ù–´–ï –î–õ–Ø –°–¢–ê–ë–ò–õ–ò–ó–ê–¶–ò–ò =====
        self.ear_history = deque(maxlen=5)
        self.face_history = deque(maxlen=5)
        self.confirmation_threshold = 3

        # ===== –ü–ï–†–ï–ú–ï–ù–ù–´–ï –°–û–°–¢–û–Ø–ù–ò–Ø =====
        self.eyes_closed_start = None
        self.alert_threshold = 2  # —á–µ—Ä–µ–∑ —Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥ –≤–∫–ª—é—á–∞–µ–º –º–µ–º
        self.total_blinks = 0
        self.prev_eye_state = True
        self.last_state_change = 0
        self.state_change_delay = 0.2

        # ===== –ù–û–í–´–ï –ü–†–ï–ú–ï–ù–ù–´–ï –î–õ–Ø –í–ò–î–ï–û =====
        self.meme_thread = None  # –ø–æ—Ç–æ–∫ —Å –º–µ–º–æ–º
        self.meme_playing = False  # –∏–≥—Ä–∞–µ—Ç –ª–∏ –º–µ–º —Å–µ–π—á–∞—Å
        self.meme_window_name = "üí© –ú–ï–ú–ù–û–ï –í–ò–î–û–°–û–í–û üí©"  # –Ω–∞–∑–≤–∞–Ω–∏–µ –æ–∫–Ω–∞
        self.meme_video_path = "meme.mp4"  # –ø—É—Ç—å –∫ –º–µ–º–Ω–æ–º—É –≤–∏–¥–µ–æ (–º–æ–∂–Ω–æ –ø–æ–º–µ–Ω—è—Ç—å)

        # ===== –ü–û–†–û–ì –ò–ó –í–ê–®–ò–• –î–ê–ù–ù–´–• =====
        self.ear_open = 0.17
        self.ear_closed = 0.13
        self.eye_threshold = (self.ear_open + self.ear_closed) / 2
        print(f"–ü–æ—Ä–æ–≥ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {self.eye_threshold:.3f}")

        # ===== –î–õ–Ø –†–£–°–°–ö–ò–• –ë–£–ö–í =====
        self.setup_russian_font()

        # ===== –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø MEDIAPIPE =====
        self.setup_mediapipe()

        print("\n" + "=" * 50)
        print("–î–ï–¢–ï–ö–¢–û–† –ó–ê–ü–£–©–ï–ù")
        print(f"MediaPipe version: {mp.__version__}")
        print("=" * 50)
        print(f"EAR –æ—Ç–∫—Ä—ã—Ç—ã—Ö: {self.ear_open}")
        print(f"EAR –∑–∞–∫—Ä—ã—Ç—ã—Ö: {self.ear_closed}")
        print(f"–ü–æ—Ä–æ–≥: {self.eye_threshold}")
        print(f"–ú–µ–º –≤–∫–ª—é—á–∏—Ç—Å—è —á–µ—Ä–µ–∑: {self.alert_threshold} —Å–µ–∫")
        print("=" * 50)

    def play_meme_video(self):
        """
        –ü—Ä–æ–∏–≥—Ä—ã–≤–∞–µ—Ç –º–µ–º–Ω–æ–µ –≤–∏–¥–µ–æ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –æ–∫–Ω–µ
        –ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Ñ–∞–π–ª —Å –≤–∏–¥–µ–æ
        if not os.path.exists(self.meme_video_path):
            print(f"‚ùå –í–∏–¥–µ–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ: {self.meme_video_path}")
            print("–ü–æ–ª–æ–∂–∏—Ç–µ —Ñ–∞–π–ª meme.mp4 –≤ –ø–∞–ø–∫—É —Å –ø—Ä–æ–≥—Ä–∞–º–º–æ–π")
            return

        # –û—Ç–∫—Ä—ã–≤–∞–µ–º –≤–∏–¥–µ–æ
        cap = cv2.VideoCapture(self.meme_video_path)
        self.meme_playing = True

        # –ü–æ–ª—É—á–∞–µ–º FPS –≤–∏–¥–µ–æ –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è
        fps = cap.get(cv2.CAP_PROP_FPS)
        delay = int(1000 / fps)  # –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∫–∞–¥—Ä–∞–º–∏ –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö

        print(f"üé¨ –ú–ï–ú –ó–ê–ü–£–©–ï–ù! –í–∏–¥–µ–æ: {self.meme_video_path}")

        while self.meme_playing:
            ret, frame = cap.read()
            if not ret:
                # –ï—Å–ª–∏ –≤–∏–¥–µ–æ –∑–∞–∫–æ–Ω—á–∏–ª–æ—Å—å, –Ω–∞—á–∏–Ω–∞–µ–º —Å–Ω–∞—á–∞–ª–∞
                cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                continue

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤–∏–¥–µ–æ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –æ–∫–Ω–µ
            cv2.imshow(self.meme_window_name, frame)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–∂–∞—Ç–∏–µ –∫–ª–∞–≤–∏—à –≤ –æ–∫–Ω–µ —Å –º–µ–º–æ–º
            key = cv2.waitKey(delay) & 0xFF
            if key == 27:  # ESC - –∑–∞–∫—Ä—ã—Ç—å –º–µ–º
                break
            elif key == ord(' '):  # –ø—Ä–æ–±–µ–ª - –ø–∞—É–∑–∞
                cv2.waitKey(0)

        # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º —Ä–µ—Å—É—Ä—Å—ã
        cap.release()
        cv2.destroyWindow(self.meme_window_name)
        self.meme_playing = False
        print("üé¨ –ú–µ–º –∑–∞–∫–æ–Ω—á–∏–ª—Å—è")

    def stop_meme(self):
        """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –ø—Ä–æ–∏–≥—Ä—ã–≤–∞–Ω–∏–µ –º–µ–º–∞"""
        if self.meme_playing:
            self.meme_playing = False
            if self.meme_thread and self.meme_thread.is_alive():
                self.meme_thread.join(timeout=1.0)

    def download_model(self):
        """–°–∫–∞—á–∏–≤–∞–µ—Ç –º–æ–¥–µ–ª—å FaceLandmarker –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç"""
        model_url = "https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task"
        model_path = "face_landmarker.task"

        if not os.path.exists(model_path):
            print("–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ FaceLandmarker...")
            try:
                urllib.request.urlretrieve(model_url, model_path)
                print("‚úì –ú–æ–¥–µ–ª—å —Å–∫–∞—á–∞–Ω–∞")
            except Exception as e:
                print(f"‚úó –û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: {e}")
                return None

        return model_path

    def setup_mediapipe(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ MediaPipe"""
        try:
            model_path = self.download_model()
            if model_path is None:
                raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –º–æ–¥–µ–ª—å")

            base_options = python.BaseOptions(model_asset_path=model_path)
            options = vision.FaceLandmarkerOptions(
                base_options=base_options,
                running_mode=vision.RunningMode.VIDEO,
                num_faces=1,
                min_face_detection_confidence=0.3,
                min_face_presence_confidence=0.3,
                min_tracking_confidence=0.3,
                output_face_blendshapes=False,
                output_facial_transformation_matrixes=False,
            )

            self.detector = vision.FaceLandmarker.create_from_options(options)
            print("‚úì MediaPipe –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞ MediaPipe: {e}")
            print("–ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥...")
            self.setup_simple_mediapipe()

    def setup_simple_mediapipe(self):
        """–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ —Å –ø—Ä–æ—Å—Ç—ã–º FaceMesh"""
        try:
            self.mp_face_mesh = mp.solutions.face_mesh
            self.face_mesh = self.mp_face_mesh.FaceMesh(
                static_image_mode=False,
                max_num_faces=1,
                refine_landmarks=True,
                min_detection_confidence=0.3,
                min_tracking_confidence=0.3
            )
            self.use_simple_mp = True
            print("‚úì –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–æ—Å—Ç–æ–π FaceMesh")
        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞: {e}")
            raise

    def setup_russian_font(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —à—Ä–∏—Ñ—Ç–∞ –¥–ª—è —Ä—É—Å—Å–∫–∏—Ö –±—É–∫–≤"""
        try:
            font_paths = [
                "C:/Windows/Fonts/arial.ttf",
                "C:/Windows/Fonts/Calibri.ttf",
            ]

            self.font = None
            for path in font_paths:
                if os.path.exists(path):
                    self.font = ImageFont.truetype(path, 32)
                    self.font_small = ImageFont.truetype(path, 24)
                    self.font_big = ImageFont.truetype(path, 48)
                    break

            if self.font is None:
                self.font = ImageFont.load_default()

            self.use_pil = True
        except:
            self.use_pil = False

    def put_russian_text(self, img, text, position, size=32, color=(255, 255, 255)):
        """–†–∏—Å—É–µ—Ç —Ä—É—Å—Å–∫–∏–π —Ç–µ–∫—Å—Ç"""
        if not self.use_pil:
            cv2.putText(img, text, position, cv2.FONT_HERSHEY_SIMPLEX,
                        size / 20, color, 2)
            return img

        try:
            img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
            draw = ImageDraw.Draw(img_pil)

            if size >= 48:
                font = self.font_big
            elif size >= 32:
                font = self.font
            else:
                font = self.font_small

            draw.text(position, text, font=font, fill=color[::-1])
            return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)
        except:
            cv2.putText(img, text, position, cv2.FONT_HERSHEY_SIMPLEX,
                        size / 20, color, 2)
            return img

    def calculate_ear(self, landmarks, vertical_idx, horizontal_idx, frame_shape):
        """–í—ã—á–∏—Å–ª—è–µ—Ç Eye Aspect Ratio (EAR)"""
        h, w = frame_shape[:2]

        try:
            if hasattr(landmarks, 'landmark'):
                v1 = landmarks.landmark[vertical_idx[0]]
                v2 = landmarks.landmark[vertical_idx[1]]
                h1 = landmarks.landmark[horizontal_idx[0]]
                h2 = landmarks.landmark[horizontal_idx[1]]
            else:
                v1 = landmarks[vertical_idx[0]]
                v2 = landmarks[vertical_idx[1]]
                h1 = landmarks[horizontal_idx[0]]
                h2 = landmarks[horizontal_idx[1]]

            v1_point = np.array([v1.x * w, v1.y * h])
            v2_point = np.array([v2.x * w, v2.y * h])
            h1_point = np.array([h1.x * w, h1.y * h])
            h2_point = np.array([h2.x * w, h2.y * h])

            vertical_dist = np.linalg.norm(v1_point - v2_point)
            horizontal_dist = np.linalg.norm(h1_point - h2_point)

            ear = vertical_dist / (horizontal_dist + 1e-6)
            return ear

        except Exception as e:
            return 0.3

    def draw_eye_points(self, frame, landmarks, eye_indices, color):
        """–†–∏—Å—É–µ—Ç —Ç–æ—á–∫–∏ –≤–æ–∫—Ä—É–≥ –≥–ª–∞–∑"""
        h, w = frame.shape[:2]

        try:
            for idx in eye_indices:
                if hasattr(landmarks, 'landmark'):
                    landmark = landmarks.landmark[idx]
                else:
                    landmark = landmarks[idx]
                x = int(landmark.x * w)
                y = int(landmark.y * h)
                cv2.circle(frame, (x, y), 2, color, -1)
        except:
            pass

    def process_frame(self, frame):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞"""
        if hasattr(self, 'use_simple_mp') and self.use_simple_mp:
            return self.process_frame_simple(frame)
        else:
            return self.process_frame_new(frame)

    def process_frame_new(self, frame):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞ —á–µ—Ä–µ–∑ –Ω–æ–≤—ã–π API"""
        try:
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)

            current_time_ms = int(time.time() * 1000)
            detection_result = self.detector.detect_for_video(mp_image, current_time_ms)

            face_detected = False
            ear_value = 0.3

            if detection_result.face_landmarks:
                face_detected = True
                landmarks = detection_result.face_landmarks[0]

                left_ear = self.calculate_ear(
                    landmarks,
                    self.LEFT_EYE_VERTICAL,
                    self.LEFT_EYE_HORIZONTAL,
                    frame.shape
                )

                right_ear = self.calculate_ear(
                    landmarks,
                    self.RIGHT_EYE_VERTICAL,
                    self.RIGHT_EYE_HORIZONTAL,
                    frame.shape
                )

                ear_value = (left_ear + right_ear) / 2.0

                self.draw_eye_points(frame, landmarks, self.LEFT_EYE_INDICES, (0, 255, 0))
                self.draw_eye_points(frame, landmarks, self.RIGHT_EYE_INDICES, (0, 255, 0))

            return frame, face_detected, ear_value
        except Exception as e:
            return frame, False, 0.3

    def process_frame_simple(self, frame):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞ —á–µ—Ä–µ–∑ –ø—Ä–æ—Å—Ç–æ–π FaceMesh"""
        try:
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = self.face_mesh.process(rgb_frame)

            face_detected = False
            ear_value = 0.3

            if results.multi_face_landmarks:
                face_detected = True
                landmarks = results.multi_face_landmarks[0]

                left_ear = self.calculate_ear(
                    landmarks,
                    self.LEFT_EYE_VERTICAL,
                    self.LEFT_EYE_HORIZONTAL,
                    frame.shape
                )

                right_ear = self.calculate_ear(
                    landmarks,
                    self.RIGHT_EYE_VERTICAL,
                    self.RIGHT_EYE_HORIZONTAL,
                    frame.shape
                )

                ear_value = (left_ear + right_ear) / 2.0

                self.draw_eye_points(frame, landmarks, self.LEFT_EYE_INDICES, (0, 255, 0))
                self.draw_eye_points(frame, landmarks, self.RIGHT_EYE_INDICES, (0, 255, 0))

            return frame, face_detected, ear_value
        except Exception as e:
            return frame, False, 0.3

    def run(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª"""
        cap = cv2.VideoCapture(0)
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

        prev_time = time.time()
        fps = 0

        while True:
            ret, frame = cap.read()
            if not ret:
                break

            current_time = time.time()
            fps = 1 / (current_time - prev_time)
            prev_time = current_time

            frame = cv2.flip(frame, 1)

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞
            frame, face_detected, ear_value = self.process_frame(frame)

            # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é
            self.face_history.append(face_detected)
            self.ear_history.append(ear_value)

            # –°–≥–ª–∞–∂–µ–Ω–Ω—ã–π EAR
            smoothed_ear = sum(self.ear_history) / len(self.ear_history)

            # –°—Ç–∞–±–∏–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ª–∏—Ü–∞
            stable_face = sum(self.face_history) >= self.confirmation_threshold

            # –õ–æ–≥–∏–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è
            if stable_face:
                eyes_closed = smoothed_ear < self.eye_threshold

                if current_time - self.last_state_change > self.state_change_delay:

                    if eyes_closed:
                        # –ì–õ–ê–ó–ê –ó–ê–ö–†–´–¢–´
                        if self.eyes_closed_start is None:
                            self.eyes_closed_start = current_time
                            self.last_state_change = current_time

                            if self.prev_eye_state:
                                self.total_blinks += 1
                                print(f"üëÅ –ú–æ—Ä–≥! –í—Å–µ–≥–æ: {self.total_blinks}")

                            self.prev_eye_state = False

                        closed_duration = current_time - self.eyes_closed_start

                        frame = self.put_russian_text(
                            frame,
                            f"–ì–õ–ê–ó–ê –ó–ê–ö–†–´–¢–´! {closed_duration:.1f}—Å",
                            (50, 50), 36, (0, 0, 255)
                        )

                        # ===== –í–ö–õ–Æ–ß–ê–ï–ú –ú–ï–ú =====
                        if closed_duration > self.alert_threshold:
                            # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –Ω–∞ —ç–∫—Ä–∞–Ω
                            frame = self.put_russian_text(
                                frame,
                                "üé¨ –°–ï–ô–ß–ê–° –ë–£–î–ï–¢ –ú–ï–ú! üé¨",
                                (50, 100), 48, (0, 255, 255)
                            )

                            # –ï—Å–ª–∏ –º–µ–º –µ—â–µ –Ω–µ –∏–≥—Ä–∞–µ—Ç - –∑–∞–ø—É—Å–∫–∞–µ–º
                            if not self.meme_playing:
                                print("üé¨ –í–ö–õ–Æ–ß–ê–ï–ú –ú–ï–ú!!!")
                                self.meme_thread = threading.Thread(target=self.play_meme_video, daemon=True)
                                self.meme_thread.start()
                    else:
                        # –ì–õ–ê–ó–ê –û–¢–ö–†–´–¢–´
                        if self.eyes_closed_start is not None:
                            self.last_state_change = current_time

                        self.eyes_closed_start = None
                        self.prev_eye_state = True

                        # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –º–µ–º –µ—Å–ª–∏ –∏–≥—Ä–∞–µ—Ç
                        if self.meme_playing:
                            print("üëÄ –ì–ª–∞–∑–∞ –æ—Ç–∫—Ä—ã—Ç—ã, –≤—ã–∫–ª—é—á–∞–µ–º –º–µ–º")
                            self.stop_meme()

                        frame = self.put_russian_text(
                            frame,
                            "–ì–õ–ê–ó–ê –û–¢–ö–†–´–¢–´",
                            (50, 50), 36, (0, 255, 0)
                        )
            else:
                frame = self.put_russian_text(
                    frame,
                    "–õ–ò–¶–û –ù–ï –û–ë–ù–ê–†–£–ñ–ï–ù–û",
                    (50, 50), 32, (128, 128, 128)
                )
                # –ï—Å–ª–∏ –ª–∏—Ü–æ –ø—Ä–æ–ø–∞–ª–æ, –≤—ã–∫–ª—é—á–∞–µ–º –º–µ–º
                if self.meme_playing:
                    self.stop_meme()

            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
            stats = [
                f"–ú–æ—Ä–≥–∞–Ω–∏–π: {self.total_blinks}",
                f"EAR: {smoothed_ear:.3f}",
                f"–ü–æ—Ä–æ–≥: {self.eye_threshold:.3f}",
                f"–°–æ—Å—Ç–æ—è–Ω–∏–µ: {'–ó–ê–ö–†–´–¢–´' if smoothed_ear < self.eye_threshold else '–û–¢–ö–†–´–¢–´'}",
                f"–ú–µ–º: {'–ò–ì–†–ê–ï–¢' if self.meme_playing else '–í–´–ö–õ'}"
            ]

            for i, stat in enumerate(stats):
                frame = self.put_russian_text(
                    frame, stat, (50, 150 + i * 30), 24, (255, 255, 255)
                )

            # –ì—Ä–∞—Ñ–∏–∫
            self.draw_ear_graph(frame, smoothed_ear, self.eye_threshold)

            # –ü–æ–¥—Å–∫–∞–∑–∫–∏
            frame = self.put_russian_text(
                frame, "ESC - –≤—ã—Ö–æ–¥ | R - —Å–±—Ä–æ—Å", (50, 460), 20, (150, 150, 150)
            )

            cv2.imshow('Eye Detector', frame)

            key = cv2.waitKey(1) & 0xFF
            if key == 27:
                break
            elif key == ord('r') or key == ord('–∫'):
                self.total_blinks = 0
                print("–°—á–µ—Ç—á–∏–∫ —Å–±—Ä–æ—à–µ–Ω")

        # –û—á–∏—Å—Ç–∫–∞ –ø—Ä–∏ –≤—ã—Ö–æ–¥–µ
        self.stop_meme()
        cap.release()
        cv2.destroyAllWindows()

        print(f"\n–í—Å–µ–≥–æ –º–æ—Ä–≥–∞–Ω–∏–π: {self.total_blinks}")

    def draw_ear_graph(self, frame, current_ear, threshold):
        """–†–∏—Å—É–µ—Ç –≥—Ä–∞—Ñ–∏–∫ EAR"""
        graph_x = 50
        graph_y = 350
        graph_w = 400
        graph_h = 30

        cv2.rectangle(frame, (graph_x, graph_y),
                      (graph_x + graph_w, graph_y + graph_h),
                      (50, 50, 50), -1)
        cv2.rectangle(frame, (graph_x, graph_y),
                      (graph_x + graph_w, graph_y + graph_h),
                      (200, 200, 200), 1)

        bar_width = int((current_ear / 0.5) * graph_w)
        bar_width = min(bar_width, graph_w)

        color = (0, 255, 0) if current_ear > threshold else (0, 0, 255)
        cv2.rectangle(frame, (graph_x, graph_y),
                      (graph_x + bar_width, graph_y + graph_h),
                      color, -1)

        threshold_x = graph_x + int((threshold / 0.5) * graph_w)
        cv2.line(frame, (threshold_x, graph_y - 5),
                 (threshold_x, graph_y + graph_h + 5),
                 (255, 255, 0), 2)

        cv2.putText(frame, f"EAR: {current_ear:.3f}", (graph_x, graph_y - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)


if __name__ == "__main__":
    detector = ModernMediaPipeEyeDetector()
    detector.run()